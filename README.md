# Thái Phạm Công

## Professional Summary

Fullstack Developer transitioning into Data Engineering with a strong foundation in modern web technologies and growing expertise in data infrastructure. Currently expanding skills in data pipelines, distributed systems, and machine learning operations to build scalable data solutions.

## Current Focus

Building expertise at the intersection of software engineering and data engineering:

- Designing and implementing ETL/ELT data pipelines for large-scale data processing
- Developing real-time streaming data applications using Apache Kafka and event-driven architectures
- Creating data warehouse solutions and optimizing query performance
- Implementing CI/CD pipelines for data workflows and infrastructure as code
- Exploring MLOps practices for model deployment and monitoring
- Studying distributed computing frameworks for big data processing

## Technical Expertise

### Data Engineering & Infrastructure

**Data Processing & Pipelines**
- Apache Airflow for workflow orchestration and scheduling
- Apache Kafka for real-time data streaming and event processing
- Apache Spark for distributed data processing and analytics
- dbt (data build tool) for analytics engineering and transformation
- Python data stack: Pandas, NumPy, Polars for data manipulation

**Databases & Data Warehousing**
- PostgreSQL with advanced query optimization and indexing strategies
- MongoDB for document-based data storage and aggregation pipelines
- MySQL for transactional data management
- Experience with columnar databases and data lake architectures
- Understanding of data modeling: star schema, snowflake schema, data vault

**Cloud & DevOps**
- Docker and Docker Compose for containerization of data applications
- Kubernetes fundamentals for container orchestration
- CI/CD pipeline design using GitHub Actions and GitLab CI
- Infrastructure as Code principles with Terraform (learning)
- Cloud platforms: AWS (S3, Lambda, RDS), GCP basics

### Software Development

**Backend Development**
- NodeJS and Express for building RESTful APIs and microservices
- NestJS framework for scalable server-side applications
- Go programming for high-performance backend services
- API design principles and GraphQL basics
- Microservices architecture and domain-driven design

**Frontend Development**
- React and NextJS for building modern web applications
- TypeScript for type-safe application development
- HTML5, CSS3, and modern JavaScript (ES6+)
- State management with Redux and React Context
- Server-side rendering and static site generation

**Development Tools & Practices**
- Git version control and collaborative development workflows
- VSCode and IntelliJ IDEA for productive development
- Test-driven development and unit testing frameworks
- Code review practices and documentation
- Agile methodologies and project management

## Current Learning Path

**Data Engineering Specialization**
```
Apache Airflow        ████████░░░░░░░░░░ 40%
Apache Kafka          ██████░░░░░░░░░░░░ 30%
Apache Spark          █████░░░░░░░░░░░░░ 25%
Data Warehousing      ███████░░░░░░░░░░░ 35%
Distributed Systems   ████░░░░░░░░░░░░░░ 20%
```

**Core Development Skills**
```
React                 ███████████████░░░ 75%
TypeScript            ██████████████░░░░ 70%
NodeJS                ██████████████░░░░ 70%
NestJS                ████████████░░░░░░ 60%
Go                    ██████████░░░░░░░░ 50%
```

**Data & DevOps**
```
PostgreSQL            ████████████░░░░░░ 60%
MongoDB               ████████████░░░░░░ 60%
Docker                ███████████░░░░░░░ 55%
Python Data Stack     ██████████░░░░░░░░ 50%
Cloud Platforms       ████████░░░░░░░░░░ 40%
```

## Professional Goals

**Short-term objectives (2025):**
- Master Apache Airflow for production-grade data pipeline orchestration
- Build real-time data streaming applications with Kafka
- Implement end-to-end ETL pipelines for data warehouse solutions
- Contribute to open-source data engineering projects
- Obtain relevant certifications in cloud data engineering (AWS/GCP)

**Long-term vision:**
- Become a proficient Data Engineer capable of architecting large-scale data platforms
- Develop expertise in machine learning operations and model deployment
- Build real-time analytics systems serving millions of users
- Create tools and frameworks that improve data engineering workflows
- Mentor junior developers transitioning into data engineering

## Project Interests

Actively seeking to work on projects involving:

- Building data lakes and lakehouses with modern data stack technologies
- Real-time data processing and streaming analytics applications
- Data quality frameworks and automated testing for data pipelines
- MLOps platforms for seamless model training and deployment
- Open-source contributions to data engineering tools and libraries
- Cross-functional data products serving analytics and machine learning teams

## GitHub Activity

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=phamcongthai&show_icons=true&theme=radical&hide_border=true&include_all_commits=true&count_private=true)

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=phamcongthai&layout=compact&theme=radical&hide_border=true&langs_count=8)

![GitHub Streak](https://github-readme-streak-stats.herokuapp.com/?user=phamcongthai&theme=radical&hide_border=true)

![Activity Graph](https://github-readme-activity-graph.vercel.app/graph?username=phamcongthai&theme=redical&hide_border=true)

## Collaboration & Contact

Open to collaborating on data engineering projects, contributing to open-source initiatives, and connecting with professionals in the data engineering community. Particularly interested in:

- Data pipeline architecture and optimization challenges
- Real-time streaming data use cases
- Data quality and observability tooling
- Cloud-native data platform design
- Cross-disciplinary projects combining software engineering and data science

Feel free to explore my repositories to see my learning journey and project work. Always eager to discuss data engineering patterns, best practices, and emerging technologies in the data space.

---

*Building the future of data-driven applications, one pipeline at a time.*
